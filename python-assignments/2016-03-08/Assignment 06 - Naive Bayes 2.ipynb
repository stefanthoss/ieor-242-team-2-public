{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IEOR 242 Assignment 06\n",
    "Classify MDA sections of 10-K reports with scikit learn Naive Bayes and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import cross_validation, preprocessing\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Path to MDA section files\n",
    "REPORT_PATH = 'mdna_sections/*'\n",
    "\n",
    "# Path to classification file\n",
    "CLASSIFICATION_FILE = 'MDNA_auto_classification_week6.2.csv'\n",
    "\n",
    "# Maximum number of features for the Bayes classifier\n",
    "MAX_FEATURE_COUNT = 5000\n",
    "\n",
    "# Minimum and maximum n for n-grams\n",
    "N_GRAMS_MIN = 1\n",
    "N_GRAMS_MAX = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Loading the MDA extracts and auto classification file from last week's assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Val1</th>\n",
       "      <th>Val2</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999_Q1_1000697_WATERS CORP -DE-_10-K_1999-03-31</td>\n",
       "      <td>WAT</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.18534</td>\n",
       "      <td>68.470588</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999_Q1_1030339_NANOGEN INC_10-K_1999-03-29</td>\n",
       "      <td>NGEN</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.18534</td>\n",
       "      <td>-7.272727</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999_Q1_1038133_HESKA CORP_10-K_1999-03-29</td>\n",
       "      <td>HSKA</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.18534</td>\n",
       "      <td>86.486486</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999_Q1_741815_HOOPER HOLMES INC_10-K_1999-03-31</td>\n",
       "      <td>HH</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.18534</td>\n",
       "      <td>-26.993865</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999_Q1_749647_CELSION CORP_10-K_1999-01-13</td>\n",
       "      <td>CLSN</td>\n",
       "      <td>1999</td>\n",
       "      <td>1.18534</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          File Name Ticker  Year     Val1  \\\n",
       "0  1999_Q1_1000697_WATERS CORP -DE-_10-K_1999-03-31    WAT  1999  1.18534   \n",
       "1       1999_Q1_1030339_NANOGEN INC_10-K_1999-03-29   NGEN  1999  1.18534   \n",
       "2        1999_Q1_1038133_HESKA CORP_10-K_1999-03-29   HSKA  1999  1.18534   \n",
       "3  1999_Q1_741815_HOOPER HOLMES INC_10-K_1999-03-31     HH  1999  1.18534   \n",
       "4       1999_Q1_749647_CELSION CORP_10-K_1999-01-13   CLSN  1999  1.18534   \n",
       "\n",
       "        Val2 Review  \n",
       "0  68.470588    pos  \n",
       "1  -7.272727    neg  \n",
       "2  86.486486    pos  \n",
       "3 -26.993865    neg  \n",
       "4  11.538462    pos  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load file with manual classifications\n",
    "class_df = pd.read_csv(CLASSIFICATION_FILE)\n",
    "class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reports: 536\n"
     ]
    }
   ],
   "source": [
    "# List with all file contents\n",
    "file_contents = list()\n",
    "\n",
    "# List with all classification labels\n",
    "labels = list()\n",
    "\n",
    "for fname in glob.iglob(REPORT_PATH):\n",
    "    if fname != '':\n",
    "        label_row = class_df.loc[class_df['File Name'] == fname.split('/')[-1].replace('mdna_', ''), 'Review']\n",
    "        if len(label_row) > 0:\n",
    "            labels.append(label_row.values[0])\n",
    "            with open(fname, 'r') as file:\n",
    "                file_contents.append(file.read())\n",
    "print('Number of reports: %d' % len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifier with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes classifier (use alpha for regularization)\n",
    "classifier = MultinomialNB(fit_prior=False)               \n",
    "\n",
    "# Initialize vectorizer module\n",
    "vectorizer = CountVectorizer(analyzer='word',\n",
    "                             stop_words='english',\n",
    "                             max_features=MAX_FEATURE_COUNT,\n",
    "                             ngram_range=(N_GRAMS_MIN, N_GRAMS_MAX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do cross validation with k=10\n",
    "cv = cross_validation.KFold(len(file_contents), n_folds=10, shuffle=True, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 5000\n",
      "[[177  60]\n",
      " [100 198]]\n",
      "Number of features: 5000\n",
      "[[172  60]\n",
      " [ 99 198]]\n",
      "Number of features: 5000\n",
      "[[168  57]\n",
      " [ 93 185]]\n",
      "Number of features: 5000\n",
      "[[168  58]\n",
      " [ 95 188]]\n",
      "Number of features: 5000\n",
      "[[175  60]\n",
      " [ 99 195]]\n",
      "Number of features: 5000\n",
      "[[167  58]\n",
      " [ 96 180]]\n",
      "Number of features: 5000\n",
      "[[172  59]\n",
      " [ 96 184]]\n",
      "Number of features: 5000\n",
      "[[159  55]\n",
      " [ 91 174]]\n",
      "Number of features: 5000\n",
      "[[163  56]\n",
      " [ 92 175]]\n",
      "Number of features: 5000\n",
      "[[172  60]\n",
      " [ 98 195]]\n"
     ]
    }
   ],
   "source": [
    "# Pandas dataframe to store the cross validation results\n",
    "eval_df = pd.DataFrame(columns=['Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "for traincv, testcv in cv:\n",
    "    # Transform the data and train the classifier\n",
    "    matrix = vectorizer.fit_transform(file_contents)\n",
    "    classifier.fit(matrix[traincv[0]:traincv[len(traincv)-1]], labels[traincv[0]:traincv[len(traincv)-1]])\n",
    "    print('Number of features: %d' % len(vectorizer.get_feature_names()))\n",
    "\n",
    "    # Build predicted and true classification labels as binary vectors\n",
    "    y_true = label_binarize(labels[testcv[0]:testcv[len(testcv)-1]], classes=['neg', 'pos'])\n",
    "    y_pred = label_binarize(classifier.predict(matrix[testcv[0]:testcv[len(testcv)-1]]), classes=['neg', 'pos'])\n",
    "\n",
    "    # Evaluate the classifier performance\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    eval_df.loc[len(eval_df)] = [accuracy_score(y_true, y_pred),\n",
    "                                 precision_score(y_true, y_pred),\n",
    "                                 recall_score(y_true, y_pred),\n",
    "                                 f1_score(y_true, y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.664430</td>\n",
       "      <td>0.712230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.699433</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.713514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.701789</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.665468</td>\n",
       "      <td>0.711538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.699411</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.710775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.699433</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.663265</td>\n",
       "      <td>0.710383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.692615</td>\n",
       "      <td>0.756303</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.700389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.696673</td>\n",
       "      <td>0.757202</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.703633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.695198</td>\n",
       "      <td>0.759825</td>\n",
       "      <td>0.656604</td>\n",
       "      <td>0.704453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.695473</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.655431</td>\n",
       "      <td>0.702811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.699048</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.665529</td>\n",
       "      <td>0.711679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score\n",
       "0  0.700935   0.767442  0.664430  0.712230\n",
       "1  0.699433   0.767442  0.666667  0.713514\n",
       "2  0.701789   0.764463  0.665468  0.711538\n",
       "3  0.699411   0.764228  0.664311  0.710775\n",
       "4  0.699433   0.764706  0.663265  0.710383\n",
       "5  0.692615   0.756303  0.652174  0.700389\n",
       "6  0.696673   0.757202  0.657143  0.703633\n",
       "7  0.695198   0.759825  0.656604  0.704453\n",
       "8  0.695473   0.757576  0.655431  0.702811\n",
       "9  0.699048   0.764706  0.665529  0.711679"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.698001\n",
       "Precision    0.762389\n",
       "Recall       0.661102\n",
       "F1 Score     0.708141\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average classifier performance\n",
    "eval_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
